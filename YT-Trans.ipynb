{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b50075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shruthika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t h i s   i s   e a r t h   t h i s   i s   w h e r e   y o u   l i v e   a n d   t h i s   i s   w h e r e   y o u   l i v e   i n   y o u r   n e i g h b o r h o o d   t h e   s o l a r   s y s t e m   [ a p p l a u s e ]   h e r e ' s   t h e   d i s t a n c e   b e t w e e n   t h e   e a r t h   a n d   t h e   m o o n   d o e s n ' t   l o o k   t o o   f a r   d o e s   i t   t h i n k   a g a i n   a t   t h e i r   f a r t h e s t   p o i n t   t h e   e a r t h   a n d   t h e   m o o n   a r e   t w o   h u n d r e d   a n d   f i f t y   t w o   t h o u s a n d   e i g h t y   e i g h t   m i l e s   a w a y   i n s i d e   t h a t   d i s t a n c e   y o u   c o u l d   f i t   e v e r y   p l a n e t   i n   o u r   e n t i r e   s o l a r   s y s t e m   b u t   l e t ' s   t a l k   a b o u t   p l a n e t s   t h e   g r e a t   r e d   s p o t   o n   j u p i t e r   t h a t ' s   a b o u t   t w o   t i m e s   a s   b i g   a s   e a r t h   a n d   s a t u r n   i s   a b o u t   n i n e   t i m e s   w i d e r   t h a n   e a r t h   s a t u r n ' s   r i n g s   a r e   s o   l a r g e   t h a t   a   f e w   o f   t h e   f r a g m e n t s   w i t h i n   t h e m   a r e   a s   l a r g e   a s   m o u n t a i n s   b u t   t h a t ' s   n o t h i n g   c o m p a r e d   t o   o u r   s u n   j u s t   r e m e m b e r   t h i s   i s   e a r t h   a n d   t h i s   i s   e a r t h   f r o m   t h e   m o o n   t h i s   i s   e a r t h   f r o m   m a r s   h e r e ' s   e a r t h   f r o m   j u s t   b e h i n d   s a t u r n ' s   r i n g s   a n d   h e r e ' s   e a r t h   f r o m   j u s t   b e y o n d   n e p t u n e   f o u r   b i l l i o n   m i l e s   a w a y   b u t   a   b i l l i o n   i s   a   b i g   n u m b e r   s o   l e t ' s   p u t   t h a t   i n   p e r s p e c t i v e   o n e   m i l l i o n   s e c o n d s   e q u a l s   a b o u t   e l e v e n   a n d   a   h a l f   d a y s   w h e r e a s   1   b i l l i o n   s e c o n d s   e q u a l s   o v e r   3 1   y e a r s   l e t ' s   s t e p   b a c k   a   b i t   h e r e ' s   t h e   s i z e   o f   e a r t h   c o m p a r e d   w i t h   t h e   s i z e   o f   o u r   s u n   t e r r i f y i n g   r i g h t   a n d   h e r e ' s   t h a t   e x a c t   s a m e   s u n   f r o m   t h e   s u r f a c e   o f   m a r s   a s   c a r l   s a g a n   o n c e   m u s e d   t h e   t o t a l   n u m b e r   o f   s t a r s   i n   t h e   u n i v e r s e   i s   l a r g e r   t h a n   a l l   t h e   g r a i n s   o f   s a n d   o n   a l l   t h e   b e a c h e s   o f   t h e   p l a n e t   e a r t h   a n d   t h e r e   a r e   s o m e   s t a r s   o u t   t h e r e   t h a t   a r e   m u c h   m u c h   b i g g e r   t h a n   o u r   l i t t l e   w i m p y   s u n   t h e   b i g g e s t   s t a r   w e   k n o w   o f   v   y   c a n i s   m a j o r i s   i s   a b o u t   2 , 0 0 0   t i m e s   t h e   d i a m e t e r   o f   o u r   s u n   b u t   n o n e   o f   t h o s e   c o m p a r e s   t o   t h e   s i z e   o f   a   g a l a x y   i n   f a c t   i f   y o u   s h r i n k   t h e   s i z e   o f   o u r   s o l a r   s y s t e m   d o w n   t o   t h e   s i z e   o f   a   q u a r t e r   a n d   t r a n q   t h e   m i l k y   w a y   g a l a x y   d o w n   u s i n g   t h e   s a m e   s c a l e   t h e   d i a m e t e r   o f   t h e   m i l k y   w a y   w i l l   b e   r o u g h l y   t h e   s i z e   o f   t h e   u n i t e d   s t a t e s   t h a t ' s   b e c a u s e   t h e   m i l k y   w a y   g a l a x y   i s   h u g e   i t ' s   d i a m e t e r s   a b o u t   1 0 0 , 0 0 0   l i g h t - y e a r s   w i d e   w h i c h   w h e n   c o n v e r t e d   t o   m i l e s   i s   a b o u t   6 2 1   q u a d r i l l i o n   3 7 1   t r i l l i o n   1 9 2   b i l l i o n   2 3 7   m i l l i o n   t h r e e   h u n d r e d   t h i r t y   t h r e e   t h o u s a n d   e i g h t   h u n d r e d   n i n e t y   m i l e s   i n s i d e   o f   a l l   t h a t   i s   y o u   y o u   l i v e   i n   t h i s   t i n y   t i n y   p o r t i o n   o f   t h e   m i l k y   w a y   b u t   e v e n   s t i l l   o u r   g a l a x y   i s   a   l i t t l e   r u n t   c o m p a r e d   w i t h   s o m e   o t h e r s   n g c   6 7 4   f o r   a   s p i r a l   g a l a x y   s i m i l a r   t o   o u r   o w n   i s   t w i c e   a s   w i d e   a s   t h e   m i l k y   w a y   s t r e t c h i n g   o v e r   t w o   h u n d r e d   t h o u s a n d   l i g h t - y e a r s   a c r o s s   i t   i s   a   m a s s i v e   b u t   l e t ' s   t h i n k   b i g g e r   i n   t h i s   p i c t u r e   a l o n e   t a k e n   b y   t h e   h u b b l e   t e l e s c o p e   t h e r e   a r e   t h o u s a n d s   a n d   t h o u s a n d s   o f   g a l a x i e s   e a c h   c o n t a i n i n g   m i l l i o n s   o r   b i l l i o n s   o f   s t a r s   w i t h   t h e i r   o w n   p l a n e t s   s o m e   o f   t h e   o b j e c t s   s e e n   h e r e   m a y   h a v e   f o r m e d   a s   m a n y   a s   1 1   b i l l i o n   y e a r s   a g o   j u s t   t h r e e   b i l l i o n   y e a r s   a f t e r   t h e   b i g   b a n g   [ m u s i c ]   t h i s   p e r i o d   o f   t i m e   i s   c o n s i d e r e d   o n e   o f   t h e   b u s i e s t   s t a r - f o r m i n g   p e r i o d s   a n d   j u s t   k e e p   t h i s   i n   m i n d   t h a t ' s   a   p i c t u r e   o f   a   v e r y   s m a l l   s m a l l   p a r t   o f   t h e   u n i v e r s e   s o   i f   y o u   e v e r   f e e l i n g   u p s e t   a b o u t   y o u r   f a v o r i t e   s h o w   b e i n g   c a n c e l e d   o r   t h e   f a c t   t h a t   t h e y   p l a y   c h r i s t m a s   m u s i c   w a y   t o o   e a r l y   j u s t   r e m e m b e r   t h i s   i s   y o u r   h o m e   e a r t h   [ a p p l a u s e ]   [ m u s i c ]\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Function to fetch transcript from YouTube video URL\n",
    "def fetch_transcript(video_url):\n",
    "    video_id = video_url.split(\"=\")[-1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    text = ' '.join([t['text'] for t in transcript])\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    cleaned_sentences = [sentence.lower() for sentence in sentences]\n",
    "    return cleaned_sentences\n",
    "\n",
    "# Function to calculate sentence similarity using cosine similarity\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "# Function to create similarity matrix\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: # ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "# Function to generate summary\n",
    "# Function to generate summary\n",
    "def generate_summary(text, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text and tokenize\n",
    "    sentences = preprocess_text(text)\n",
    "\n",
    "    # Step 2 - Generate similarity matrix across sentences\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "\n",
    "    # Check if there are enough sentences to summarize\n",
    "    if len(ranked_sentence) < top_n:\n",
    "        top_n = len(ranked_sentence)\n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Output the summarized text\n",
    "    return \". \".join(summarize_text)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_url = \"https://www.youtube.com/watch?v=FkQWpQd9Zdo\"\n",
    "    text = fetch_transcript(video_url)\n",
    "    summary = generate_summary(text)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8df8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
